# R-Latplan: Learning Reliable PDDL Models for Classical Planning from Visual Data

> A Neuro-Symbolic Learning Framework for Visually Grounded and Executable Planning Models

![ICTAI 2024](https://img.shields.io/badge/IEEE-ICTAI_2024-blue)
![Neuro-Symbolic AI](https://img.shields.io/badge/AI-Neuro--Symbolic-brightgreen)
![License](https://img.shields.io/github/license/aymeric75/R-latplan)

## ğŸ“œ Abstract

**R-Latplan** is a novel framework that learns **reliable PDDL (Planning Domain Definition Language)** action models directly from **noisy image observations** without any expert supervision or manually annotated symbolic states. It extends the original **Latplan** system by introducing a transition identifier function that anchors learned transitions to **real-world agent actions**, ensuring **executability, interpretability, and robustness**.

This repository contains the official implementation and experimental benchmarks presented in our ICTAI 2024 paper:  
**"Learning Reliable PDDL Models for Classical Planning from Visual Data"**  
by Aymeric Barbin, Federico Cerutti, Alfonso Gerevini

[[Read the Paper (PDF)]](./Learning_Reliable_PDDL_Models_for_Classical_Planning_from_Visual_Data.pdf)

---

## ğŸš€ Highlights

- ğŸ”— **Reliable Symbolic Learning**: Learns executable action models directly linked to high-level agent capabilities.
- ğŸ§  **Neuro-Symbolic Backbone**: Integrates Variational AutoEncoders with symbolic reasoning.
- ğŸ–¼ï¸ **Visual Data Only**: Trained from image traces without human-labelled annotations.
- ğŸ§ª **Robustness to Noise**: Handles mislabeled transitions and noisy observations.
- ğŸ§© **Domain-Independent**: Validated on classic planning benchmarks (Hanoi, Blocksworld, Sokoban).

---

## ğŸ“‚ Project Structure
```bash
R-latplan/
â”œâ”€â”€ downward/                     # Fastdownward
â”œâ”€â”€ latplan/                      # Core neural networks (SAE, APPLY, REGRESS)
â”œâ”€â”€ r_latplan_datasets/           # Scripts for generating R Latplan dataset (from PDDLGym)
â”œâ”€â”€ r_latplan_exps/               # Training (weights ...) and Testing results per type of experiment (R-Latplan)
â”œâ”€â”€ r_vanilla_latplan_datasets/   # Scripts for generating Vanilla Latplan dataset (from PDDLGym)
â”œâ”€â”€ r_vanilla_latplan_exps/       # Training (weights ...) and Testing results per type of experiment (Vanilla Latplan)
â”œâ”€â”€ README.md              # This file
â””â”€â”€ paper.pdf              # The published paper
````

## ğŸ§ª Experiments & Results

We designed five experiments across three benchmark domainsâ€”**Hanoi**, **Blocksworld**, and **Sokoban**â€”to evaluate R-Latplan's reliability and robustness:

| Research Question | Objective |
|-------------------|-----------|
| **RQ1** | Does R-Latplan produce visually and semantically reliable PDDL actions even under noise? |
| **RQ2** | Can classical planners (e.g., Fast Downward) find optimal plans using learned models from noisy/incomplete traces? |
| **RQ3** | Is R-Latplan robust to errors in the transition identifier function? |

**Highlights from the results:**

- âœ… R-Latplan always links PDDL actions to real agent capabilities.
- âœ… It avoids hallucinations common in Latplan.
- âœ… Fast Downward solved all benchmark tasks with optimal plans.
- âœ… Robust against image noise and transition mislabeling.


---

## ğŸ“Š R-Latplan vs Vanilla Latplan: Executability & Robustness

We evaluated **execution success** over the longest valid paths derived from visual DFAs in:

- **Exp1**: Crisp and Complete Visual DFAs  
- **Exp2**: Noisy and Complete Visual DFAs  

The figure below reports the **% of successful executions** (maximum success = 3 test runs per configuration) across increasing problem sizes and benchmark domains:

![R-Latplan vs Vanilla Latplan Performance](./plan_perfs_finale.png)

- **Solid lines**: R-Latplan  
- **Dashed lines**: Vanilla Latplan

âœ… R-Latplan maintains near-perfect execution, even with noise.  
âŒ Vanilla Latplan struggles on long plans and under noisy conditions.

---

## ğŸ–¼ï¸ Visual Plan Comparison: R-Latplan vs Vanilla Latplan

Below is an example comparing plans generated by both systems in the **Hanoi domain**:

### âœ… R-Latplan (Visually Correct Plan)

Each image represents a valid agent-executable transition.

![R-Latplan Plan](./r_latplan_plan.png)

---

### âŒ Vanilla Latplan (Visually Incorrect Plan)

Hallucinated transitions or visual artifacts lead to execution failure.

![Vanilla Latplan Plan](./vanilla_latplan_plan.png)

---



## â–¶ï¸ Running the Experiments

### Step 1: Generate Visual Traces
```bash
python data/generate_traces.py --domain blocksworld
````
### Step 2: Train R-Latplan
```bash
python train.py --domain blocksworld --config configs/blocksworld.json
````
### Step 3: Generate PDDL Domain
```bash
python planner/generate_pddl.py --model outputs/blocksworld_model.pt
````
### Step 4: Solve with Fast Downward
```bash
python planner/run_planner.py --domain outputs/blocksworld.pddl --problem problems/blocksworld/p01.pddl
````


---

## ğŸ“œ Citation

If you use this code or build upon this work, please cite the following paper:

```bibtex
@inproceedings{barbin2024rlatplan,
  title={Learning Reliable PDDL Models for Classical Planning from Visual Data},
  author={Barbin, Aymeric and Cerutti, Federico and Gerevini, Alfonso Emilio},
  booktitle={36th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)},
  year={2024}
}
```
---

## ğŸ‘¤ Authors

- **Aymeric Barbin**  
  Doctorate in Artificial Intelligence â€“ Sapienza University of Rome  
  [aymeric.barbin@uniroma1.it](mailto:aymeric.barbin@uniroma1.it)  
  [GitHub @aymeric75](https://github.com/aymeric75)

- **Federico Cerutti**  
  University of Brescia, Italy

- **Alfonso E. Gerevini**  
  University of Brescia, Italy

